{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5417e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING CODE WITH CENTRALIZED FILE NAMING\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras._tf_keras.keras.callbacks import ReduceLROnPlateau, EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from keras._tf_keras.keras.applications.efficientnet_v2 import EfficientNetV2S # Import the corresponding application\n",
    "from keras._tf_keras.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Activation\n",
    "from keras._tf_keras.keras.models import Model\n",
    "from keras._tf_keras.keras.optimizers import Adam\n",
    "\n",
    "# üîπ Set model name in one place\n",
    "file_name = \"EfficientNetV2S\"  # Change this to rename all outputs\n",
    "\n",
    "# Dataset paths\n",
    "TRAIN_DIR = '' # Directory of the Train Data Set\n",
    "VAL_DIR = '' # Directory of the Validation Data Set\n",
    "\n",
    "if not os.path.exists(TRAIN_DIR) or not os.path.exists(VAL_DIR):\n",
    "    raise FileNotFoundError(\"Dataset directories not found!\")\n",
    "\n",
    "# Data generators\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=40,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_data_generator = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "train_set = train_data_generator.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_set = val_data_generator.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Build model with logits and softmax layer separated\n",
    "base_model = EfficientNetV2S(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "logits_layer = Dense(6, activation=None, name='logits')(x)\n",
    "softmax_output = Activation('softmax', name='predictions')(logits_layer)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=softmax_output)\n",
    "\n",
    "# Compile with label smoothing\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks using centralized file_name\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-5, verbose=1),\n",
    "    CSVLogger(f'{file_name}_log.csv'),\n",
    "    ModelCheckpoint(f'{file_name}_best.keras', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_set,\n",
    "    validation_steps=len(val_set),\n",
    "    steps_per_epoch=len(train_set),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save(f\"{file_name}_final.keras\")\n",
    "\n",
    "# Plot loss and accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cade3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALIBRATED MODEL TESTING\n",
    "# LOAD THE MODEL\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.src.saving.saving_api import load_model\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# üîπ 1. Define temperature scaling function (match model's custom Lambda)\n",
    "TEMPERATURE = 0.751  # Replace with your learned temperature if different\n",
    "\n",
    "def temperature_scaling(logits):\n",
    "    return logits / tf.constant(TEMPERATURE, dtype=tf.float32)\n",
    "\n",
    "# üîπ 2. Load calibrated model\n",
    "model = load_model(\"/home/amir/projects/TRAININGCODE/effnet_calibrated_scipy.keras\", custom_objects={\"temperature_scaling\": temperature_scaling})\n",
    "\n",
    "# üîπ 3. Prepare test data\n",
    "TEST_DIR = \"/home/amir/projects/BALANCED/val\"  # Make sure this path is correct\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,  # Predict per image for detailed confidence\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# üîπ 4. Run predictions\n",
    "probs = model.predict(test_set, verbose=1)\n",
    "predicted_classes = np.argmax(probs, axis=1)\n",
    "confidence_scores = np.max(probs, axis=1)\n",
    "true_classes = test_set.classes\n",
    "filenames = test_set.filenames\n",
    "class_indices = {v: k for k, v in test_set.class_indices.items()}\n",
    "\n",
    "# üîπ 5. Map numeric labels to class names\n",
    "true_labels = [class_indices[i] for i in true_classes]\n",
    "pred_labels = [class_indices[i] for i in predicted_classes]\n",
    "\n",
    "# üîπ 6. Save results to CSV\n",
    "df = pd.DataFrame({\n",
    "    \"filename\": filenames,\n",
    "    \"true_label\": true_labels,\n",
    "    \"predicted_label\": pred_labels,\n",
    "    \"confidence\": confidence_scores\n",
    "})\n",
    "\n",
    "df.to_csv(\"test_results_with_confidence.csv\", index=False)\n",
    "print(\"‚úÖ Results saved to 'test_results_with_confidence.csv'.\")\n",
    "\n",
    "# Optional: Print top 5 least confident predictions\n",
    "print(\"\\nüîç Top 5 least confident predictions:\")\n",
    "print(df.sort_values(by=\"confidence\").head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CALIBRRATION INTEGRATION\n",
    "# LOAD THE MODEL\n",
    "# LOOK FOR OPTIMAL TEMPERATURE\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras._tf_keras.keras.models import load_model\n",
    "\n",
    "\n",
    "# Load saved model\n",
    "# Define the same temperature used during calibration\n",
    "TEMPERATURE = 1.007\n",
    "\n",
    "# Recreate the Lambda function used in the model\n",
    "def temperature_layer(x):\n",
    "    return x / TEMPERATURE\n",
    "def temperature_scaling(logits):\n",
    "    return logits / tf.constant(TEMPERATURE, dtype=tf.float32)\n",
    "\n",
    "\n",
    "model = load_model(\"/home/amir/projects/TRAININGCODE/EfficientNetV2S_calibrated_scipy.keras\", custom_objects={\"temperature_scaling\": temperature_scaling})\n",
    "\n",
    "\n",
    "# Validation generator (same as training setup)\n",
    "VAL_DIR = r\"\" # Directory of the Validation Data Set\n",
    "val_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "val_set = val_data_generator.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important for correct label order\n",
    ")\n",
    "\n",
    "# Get true labels and predictions\n",
    "true_labels = val_set.classes\n",
    "predictions = model.predict(val_set)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "class_names = list(val_set.class_indices.keys())\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=class_names, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "steps = len(val_set)\n",
    "predictions = model.predict(val_set, steps=steps, verbose=1)\n",
    "calibrated_probs = predictions\n",
    "\n",
    "from netcal.presentation import ReliabilityDiagram\n",
    "from netcal.metrics import ECE\n",
    "\n",
    "# üîπ Compute ECE\n",
    "ece = ECE(bins=15)\n",
    "ece_score = ece.measure(calibrated_probs, true_labels)\n",
    "print(f\"üìä Calibrated ECE: {ece_score:.4f}\")\n",
    "\n",
    "# üîπ Plot Reliability Diagram\n",
    "diagram = ReliabilityDiagram(bins=15)\n",
    "diagram.plot(calibrated_probs, true_labels)\n",
    "plt.title(\"Reliability Diagram (After Temperature Scaling)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e11fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CALIBRATION\n",
    "# LOAD THE MODEL\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.src.saving.saving_api import load_model\n",
    "from netcal.metrics import ECE\n",
    "from netcal.presentation import ReliabilityDiagram\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "# CHANGE THE MODEL\n",
    "from keras.src.models.model import Model\n",
    "from keras._tf_keras.keras.applications.efficientnet_v2 import EfficientNetV2S\n",
    "\n",
    "TEMPERATURE = 0.751\n",
    "\n",
    "# üîπ Load validation set\n",
    "VAL_DIR = '/home/amir/projects/BALANCED/val'\n",
    "val_data_generator = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "val_set = val_data_generator.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# üîπ Load trained model and extract logits layer\n",
    "model = load_model(\"/home/amir/projects/TRAININGCODE/EfficientNetV2S_FocalLoss_best.keras\", compile=False)\n",
    "logits_layer = model.get_layer(\"logits\").output  # Layer with activation=None\n",
    "logits_model = Model(inputs=model.input, outputs=logits_layer)\n",
    "\n",
    "\n",
    "# üîπ Gather all validation data\n",
    "val_images, val_labels = [], []\n",
    "for _ in range(len(val_set)):\n",
    "    x, y = next(val_set)\n",
    "    val_images.append(x)\n",
    "    val_labels.append(y)\n",
    "\n",
    "val_images = np.concatenate(val_images)\n",
    "val_labels = np.concatenate(val_labels)\n",
    "\n",
    "# üîπ Get logits (pre-softmax outputs)\n",
    "val_logits = logits_model.predict(val_images, verbose=0)\n",
    "\n",
    "# üîπ Softmax with temperature function\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    exp_logits = np.exp(scaled_logits - np.max(scaled_logits, axis=1, keepdims=True))\n",
    "    return exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "\n",
    "# üîπ Define temperature scaling loss\n",
    "def temperature_loss(temperature):\n",
    "    temperature = temperature[0]\n",
    "    probs = softmax_with_temperature(val_logits, temperature)\n",
    "    log_probs = np.log(np.clip(probs, 1e-15, 1.0))\n",
    "    loss = -np.sum(val_labels * log_probs) / val_labels.shape[0]\n",
    "    return loss\n",
    "\n",
    "# üîπ Optimize temperature\n",
    "opt_result = minimize(temperature_loss, x0=[1.0], bounds=[(0.5, 10.0)], method='L-BFGS-B')\n",
    "optimal_temperature = opt_result.x[0]\n",
    "print(f\"‚úÖ Optimal Temperature: {optimal_temperature:.4f}\")\n",
    "\n",
    "# üîπ Calibrate probabilities\n",
    "calibrated_probs = softmax_with_temperature(val_logits, optimal_temperature)\n",
    "confidences = np.max(calibrated_probs, axis=1)\n",
    "pred_labels = np.argmax(calibrated_probs, axis=1)\n",
    "true_labels = np.argmax(val_labels, axis=1)\n",
    "\n",
    "# üîπ Compute ECE\n",
    "ece = ECE(bins=15)\n",
    "ece_score = ece.measure(calibrated_probs, true_labels)\n",
    "print(f\"üìä Calibrated ECE: {ece_score:.4f}\")\n",
    "\n",
    "# üîπ Plot Reliability Diagram\n",
    "diagram = ReliabilityDiagram(bins=15)\n",
    "diagram.plot(calibrated_probs, true_labels)\n",
    "plt.title(\"Reliability Diagram (After Temperature Scaling)\")\n",
    "plt.show()\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras._tf_keras.keras.applications.resnet50 import ResNet50 # Import the corresponding application\n",
    "from keras.src.layers import Input, GlobalAveragePooling2D, Dropout, Dense, Lambda, Activation\n",
    "from keras.src.models import Model\n",
    "\n",
    "# üîπ Rebuild calibrated model with temperature scaling\n",
    "input_layer = Input(shape=(224, 224, 3))\n",
    "base_model = EfficientNetV2S(include_top=False, weights='imagenet', input_tensor=input_layer)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dense(6, activation=None)(x)\n",
    "\n",
    "# üîπ Apply learned temperature\n",
    "from keras.src.layers import Lambda\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "def temperature_scaling(logits):\n",
    "    return logits / K.constant(TEMPERATURE)\n",
    "\n",
    "x = Lambda(temperature_scaling, name=\"temperature_scaled\", output_shape=(6,))(x)\n",
    "\n",
    "\n",
    "output = Activation('softmax')(x)\n",
    "calibrated_model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# üîπ Load weights from original model\n",
    "for i, layer in enumerate(calibrated_model.layers):\n",
    "    try:\n",
    "        layer.set_weights(model.layers[i].get_weights())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# üîπ Save calibrated model\n",
    "calibrated_model.save(\"EfficientNetV2S_calibrated_scipy.keras\")\n",
    "print(\"üì¶ Saved calibrated model with temperature scaling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ee11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CONVERSION\n",
    "# LOAD THE MODEL\n",
    "# CHANGE THE CORRESPONDING TEMPERATURE\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# üîπ 1. Define temperature scaling function (used in your model)\n",
    "TEMPERATURE = 1.007  # Replace with your learned temperature if different\n",
    "\n",
    "def temperature_scaling(logits):\n",
    "    return logits / tf.constant(TEMPERATURE, dtype=tf.float32)\n",
    "\n",
    "# üîπ 2. Load the temperature-scaled model\n",
    "model = tf.keras.models.load_model(\n",
    "    \"/home/amir/projects/TRAININGCODE/EfficientNetV2S_calibrated_scipy.keras\",\n",
    "    custom_objects={\"temperature_scaling\": temperature_scaling}\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully.\")\n",
    "\n",
    "# üîπ 3. Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Optional: optimize for size/performance\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Optional: ensure float32 output (important for calibrated confidence outputs)\n",
    "converter.target_spec.supported_types = [tf.float32]\n",
    "\n",
    "# Perform conversion\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# üîπ 4. Save the TFLite model\n",
    "tflite_path = \"effnet_calibrated.tflite\"\n",
    "with open(tflite_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(f\"‚úÖ TFLite model saved as '{tflite_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3975c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERTED MODEL TESTING\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# üîπ 1. Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"\") # Define Model File Directory\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_shape = input_details[0]['shape'][1:3]  # Should be (224, 224)\n",
    "input_dtype = input_details[0]['dtype']\n",
    "\n",
    "# üîπ 2. Load test set using ImageDataGenerator\n",
    "TEST_DIR = \"\" # Directory of the Test Data Set\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=input_shape,\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# üîπ 3. Run inference with TFLite model\n",
    "predicted_classes = []\n",
    "confidence_scores = []\n",
    "\n",
    "print(\"üîç Running TFLite inference on test set...\")\n",
    "\n",
    "for i in range(len(test_generator)):\n",
    "    img, label = test_generator[i]\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], img.astype(input_dtype))\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    predicted_class = np.argmax(output[0])\n",
    "    confidence = np.max(output[0])\n",
    "\n",
    "    predicted_classes.append(predicted_class)\n",
    "    confidence_scores.append(confidence)\n",
    "\n",
    "print(\"‚úÖ Inference complete.\")\n",
    "\n",
    "# üîπ 4. Save results\n",
    "filenames = test_generator.filenames\n",
    "true_classes = test_generator.classes\n",
    "class_indices = {v: k for k, v in test_generator.class_indices.items()}\n",
    "\n",
    "true_labels = [class_indices[i] for i in true_classes]\n",
    "pred_labels = [class_indices[i] for i in predicted_classes]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"filename\": filenames,\n",
    "    \"true_label\": true_labels,\n",
    "    \"predicted_label\": pred_labels,\n",
    "    \"confidence\": confidence_scores\n",
    "})\n",
    "\n",
    "df.to_csv(\"tflite_test_results.csv\", index=False)\n",
    "print(\"üìÅ Results saved to 'tflite_test_results.csv'.\")\n",
    "\n",
    "# üîç Top 5 least confident predictions\n",
    "print(\"\\nüîç Top 5 least confident predictions:\")\n",
    "print(df.sort_values(by=\"confidence\").head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf217",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
